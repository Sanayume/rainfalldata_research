# rainfalldata_research
# 高分辨率降雨融合与机器学习预测研究项目

## 1. 项目概述与研究意义

**背景:** 精准的降雨预测对于洪水预警、农业生产、水资源管理等领域至关重要。然而，单一数据源往往存在时空覆盖不完整、精度不足等问题。本项目旨在应对这一挑战，通过 **融合多种先进的卫星遥感降雨产品** (CMORPH, CHIRPS, GSMAP, IMERG, PERSIANN, SM2RAIN) 与 **地面观测融合数据** (CHM)，结合 **前沿的机器学习技术**，探索和构建高性能、高分辨率的降雨预测模型。

**目标:**
*   开发一套稳健的数据处理与融合流程，有效整合多源异构降雨数据。
*   设计并实现大规模、多维度的特征工程体系，深度挖掘数据中蕴含的降雨相关信息。
*   系统性地评估和优化多种机器学习模型（特别是梯度提升树如 XGBoost, LightGBM，并辅以贝叶斯方法等）在降雨预测任务上的性能。
*   深入分析模型误差，理解预测偏差来源，并驱动特征和模型的迭代优化。
*   针对重点区域（如长江流域）进行精细化建模，探索区域适应性预测策略。

**核心价值:** 本项目不仅致力于提升降雨预测精度，也深入探索了数据融合、特征工程和机器学习在复杂气象问题中的应用潜力，为相关领域的研究和应用提供方法论参考和技术积累。

## 2. 项目技术架构与实施细节

### 2.1 数据体系 (`data/`)

*   **多源数据整合:**
    *   **原始数据 (`raw/`)**: 涵盖 CMORPH, CHIRPS, GSMAP, IMERG, PERSIANN, SM2RAIN, CHM 等 **7 种主流降雨产品** 的原始数据（如 `.nc`, `.zip` 格式），时间跨度覆盖 **多年** (例如 2016-2020 年数据被重点处理)，空间分辨率各异，总数据量达到 **数十 GB 甚至 TB 级别**。
    *   **挑战**: 处理不同产品的格式差异、坐标系统、时间分辨率不一致等问题。
*   **精细化预处理 (`intermediate/`, `processed/`)**:
    *   **NaN 值处理**: 实施了系统的缺失值处理流程，结合了 **时空插值方法** 与 **阈值替换策略**，确保数据完整性。处理后的数据按产品和年份存储 (`intermediate/`)，并最终生成用于模型输入的合并时间序列 `.mat` 文件 (`processed/`)。
    *   **空间掩码**: 生成并应用了中国大陆及主要流域（如长江流域）的高精度地理掩码 (`processed/.../masks/`)，以精确提取研究区域数据。
    *   **标准化与对齐**: 进行了必要的时间和空间分辨率对齐操作。

### 2.2 特征工程 (`src/common/feature_engineering/`, `src/.../pipeline_feature_gen.py`)

构建了一个 **包含数百个潜在特征** 的大规模特征库，体现了对降雨物理机制和数据驱动模式的深度理解：

*   **基础信息**: 各降雨产品在目标点的原始降雨量。
*   **多产品协同**: 利用产品间的统计关系（均值、标准差、中位数、极差、一致降雨产品数）来 **量化不同产品的一致性与不确定性**，这是单一产品分析无法实现的。
*   **时序动态捕捉**:
    *   **周期性**: 采用正余弦函数编码年内周期、季节性虚拟变量等捕捉季节变化规律。
    *   **记忆性**: 引入 **多尺度时间滞后项** (t-1, t-2, t-3 天等) 捕捉降雨的持续性和短期依赖。
    *   **变化率**: 计算 **时间差分** 特征捕捉降雨强度的变化趋势。
    *   **累积效应**: 设计了 **多窗口滑动统计** (如 3, 7, 15 天窗口的均值、标准差、最值、范围) 以捕捉不同时间尺度下的降雨累积和波动特征。
*   **空间关联**: 引入 **3x3 邻域** 的空间统计量（均值、标准差、最大值）及其与中心点的差异，以 **刻画降雨事件的空间展布和局部梯度**。
*   **弱信号增强**: 特别设计了针对 **毛毛雨、小雨等低强度降雨** 的探测特征（如距 0.1mm 阈值距离、变异系数 CV、特定强度分箱），旨在提升模型对这类易被忽略但重要的降雨事件的敏感度。
*   **高阶交互**: 探索性地构建了 **交互特征** (如 `产品标准差 * 季节性因子`)，试图捕捉非线性、多因素耦合的复杂降雨模式。
*   **迭代优化**: 特征集经历了 **至少 5 个主要版本 (`v1` 到 `v5.1`) 的迭代** (`results/.../features/`)，每一版本的调整都基于前一轮的模型评估和误差分析结果，体现了 **数据驱动的特征选择和优化** 过程。

### 2.3 机器学习建模 (`src/.../pipeline_train_*.py`, `results/.../models/`)

系统性地探索和评估了多种先进的机器学习模型：

*   **主力模型**:
    *   **XGBoost / LightGBM**: 作为业界领先的梯度提升树模型，重点用于追求高预测性能，并针对性地调整了目标函数和评估指标。
*   **辅助与对比模型**:
    *   **Naive Bayes**: 作为基准模型之一，用于快速评估特征效果。
    *   **Bayesian Network**: 探索结合 **专家先验知识** (可能体现在网络结构或参数先验上) 与数据驱动学习的可能性，提升模型的可解释性。
*   **自动化超参数优化**: 广泛应用 **Optuna** 框架，对 XGBoost 和 LightGBM 等模型的 **关键超参数** (如树的深度、学习率、正则化项等) 进行了系统的 **贝叶斯优化或类似搜索**，以寻找最优模型配置。
*   **性能加速**: 积极探索 **GPU 加速** 技术 (`legacy/cuda_*.py`)，利用 CUDA 环境优化训练过程，以应对大规模数据和复杂模型的计算挑战。
*   **集成学习探索**: 进行了集成学习的初步尝试 (`src/ensemble_learning/`)，旨在结合多个模型的优势，进一步提升预测稳定性和准确性。
*   **版本化管理**: 严格保存了 **不同版本、不同参数配置** 下训练得到的模型文件 (`.joblib`, `.pkl`)，便于追溯和比较。

### 2.4 全方位评估与诊断 (`src/.../analysis/`, `results/.../plots/`)

建立了全面的模型评估和诊断体系，远超标准指标评估：

*   **标准指标**: Accuracy, Precision, Recall, F1-score, ROC AUC 等。
*   **气象相关指标**: 可能探索了如 Heidke Skill Score (HSS), Equitable Threat Score (ETS) 等专业评分。
*   **训练过程监控**: 可视化并分析 **训练/验证损失曲线**，判断模型拟合状态。
*   **特征重要性分析**: 利用模型内置方法（如 SHAP 值或 Gini 不纯度）量化和排序 **特征贡献度**，理解模型决策依据。
*   **特征相关性研究**: 计算并可视化 **特征间的相关系数矩阵**，识别冗余特征，并对比不同特征集 (`v1` vs `v2`) 的差异。
*   **误差空间分布**: 绘制 **预测误差（如偏差、均方根误差）的空间分布图**，识别模型表现的地理差异和薄弱区域。
*   **误差时间演变**: 分析误差的 **季节性变化和月度趋势**。
*   **误报/漏报 (FP/FN) 深度诊断**:
    *   识别 **FP/FN 事件高发的热点区域**。
    *   **专门分析 FP/FN 样本对应的特征分布** (`feature_of_FP_FN.py`)，反向推断导致预测错误的关键因素，为特征工程优化提供直接依据。
*   **预测阈值敏感性分析**: 系统评估不同 **分类阈值** 对 Precision, Recall 等指标的影响，为实际应用选择最佳阈值提供依据。

## 3. 项目进展时间轴 (自 2025.01.01)

项目自年初以来展现了高速迭代和持续深化的特点：

-   **Q1 (1-3月): 数据基础建设与初步探索**
    *   **关键任务**: 完成 **TB 级原始数据的收集、解析和标准化**；攻克多源数据融合的技术难点；建立 **稳健的 NaN 值处理流程** 并完成核心时段 (如 2016-2020) 的数据预处理，形成可用的 `.mat` 输入数据。
    *   **产出**: 标准化的多产品 `.mat` 数据集 (`data/intermediate`, `data/processed`)；全国地理掩码；早期版本的数据加载和处理脚本 (`scripts/preprocessing`)；初步的 XGBoost, KNN, LSTM 模型训练脚本 (`src/legacy`) 及初步结果。
    *   **挑战与应对**: 解决了大数据 I/O 效率问题；设计了兼顾效率和效果的 NaN 填充策略；开始了 GPU 加速训练的探索。
-   **Q2 (4月 - 5月初): 特征工程、模型优化与长江流域专项**
    *   **关键任务**: 进入 **特征工程密集迭代期** (`turn1.py` -> `turn5_1.py`)，基于模型反馈快速增加、筛选和调整特征；全面应用 **Optuna 进行超参数寻优**；开展 **系统性的模型评估和误差诊断**；启动并快速推进 **长江流域的专项分析与建模**。
    *   **产出**: **多个版本 (`v2` 至 `v5.1`) 的全国和长江流域特征数据集** (`results/.../features`)；大量经过 **超参数优化** 的 XGBoost, LightGBM, Bayes 等模型 (`results/.../models`)；**丰富的分析图表和报告**，涵盖特征、模型、误差等多个维度 (`results/.../plots`)；长江流域特定的全套代码和结果 (`src/yangtze`, `results/yangtze`)。
    *   **挑战与应对**: 管理庞大的特征集和实验版本；分析和解读复杂的误差模式；**并行推进全国和区域研究**；确保代码在快速迭代中的稳定性。
-   **5月初至今: 项目重构与总结**
    *   **关键任务**: 对项目 **文件结构进行全面重构**，提升组织性、可维护性和协作潜力；**系统性总结项目进展、技术细节和挑战**，为后续工作和答辩做好准备。
    *   **产出**: 当前清晰的项目目录结构；本 README 详细报告。

## 4. 项目可持续性与未来展望

本项目已奠定坚实的基础，并展现出强大的可持续发展潜力：

1.  **代码库完善与标准化**:
    *   **【近期重点】** 完成 `src/` 目录下所有脚本的 **文件路径更新**，确保代码在新结构下无缝运行。
    *   将核心功能（特别是数据加载、特征工程、模型训练）**封装为可复用的 Python 模块或包**，提升代码质量和易用性。
    *   **完善文档**: 补充详细的 `README.md`（包括环境设置、数据说明、运行指令）、代码内注释和必要的技术文档。
2.  **区域化研究深化**:
    *   深入对比长江流域与全国范围的模型表现和关键特征差异。
    *   可 **扩展到其他重要流域或气候区**，进行模型迁移性和适应性研究。
    *   考虑引入更高分辨率的 **地形地貌数据 (DEM)** 等地理因子，增强区域模型的精度。
3.  **特征工程与模型前沿探索**:
    *   **特征**: 探索更复杂的时空特征（如 ConvLSTM 提取的时空模式）、引入大气环流因子、探索基于物理过程的特征构建。
    *   **模型**: 深入研究 **深度学习模型** (如 CNN, Transformer, ConvLSTM) 在该任务上的应用；探索 **可解释性 AI (XAI)** 技术增强模型透明度；进一步优化 **集成学习** 策略；尝试 **多任务学习** 或 **迁移学习**。
4.  **应用潜力与拓展**:
    *   **准实时预测系统**: 探索构建接近实时的短临降雨预测流程。
    *   **极端事件预警**: 针对性优化模型对暴雨等极端降雨事件的预测能力。
    *   **与其他模型耦合**: 探索将本项目预测结果作为输入，驱动水文模型或其他下游应用模型。
5.  **工程实践**:
    *   **引入 Git 进行版本控制**: 强烈建议立即实施，规范管理代码和实验历史。
    *   **构建自动化流水线 (Pipeline)**: 利用 Airflow, Kubeflow 等工具实现数据处理、特征工程、模型训练、评估的自动化流程。

**结论:** 本项目在多源降雨数据融合、大规模特征工程、机器学习建模与深度诊断方面开展了系统性的研究和实践，取得了丰富的阶段性成果，并已构建了一个可持续发展、潜力巨大的研究框架。项目展现了研究者在处理复杂气象数据、应用先进机器学习技术以及系统性解决科学问题方面的综合能力。

